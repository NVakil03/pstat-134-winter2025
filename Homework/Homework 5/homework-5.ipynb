{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ca6ea35-af0d-4805-9e3f-99b862802b1a",
   "metadata": {},
   "source": [
    "## Homework 5\n",
    "\n",
    "**Note: If this is one of your two late homework submissions, please indicate below; also indicate whether it is your first or second late submission.**\n",
    "\n",
    "\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\n",
    "\n",
    "This homework assignment has **two parts**. In the first, you will practice building a recommender system; in the second, you'll practice training a neural network for image classification. I strongly advise using Lab 8 and Lab 9 for assistance as you work on this assignment. Make sure to **read the entire assignment**.\n",
    "\n",
    "You also may need to use other functions. I encourage you to make use of available resources (including the Internet) to help you solve these problems. You can also work with your classmates. If you do work together, you must provide the names of those classmates below.\n",
    "\n",
    "[Names of Collaborators (if any):]{.underline}\n",
    "\n",
    "### Recommender Systems\n",
    "\n",
    "We'll work with the data in `data/movies.csv` and `data/movie-ratings.csv`. `movies` contains a list of $9,737$ movies and their basic description â€“ title, year of release, and genres, separated by vertical bars (for example, `Comedy|Romance`). `movie-ratings` contains ratings of movies by $610$ users, on a scale from $0$ to $5$.\n",
    "\n",
    "The data come from this source at Kaggle: <https://www.kaggle.com/datasets/gargmanas/movierecommenderdataset/>\n",
    "\n",
    "#### Exercise 1\n",
    "\n",
    "Read both data files into Python. (You can also use R, if you prefer. If you do use R, I would recommend working with a smaller subset of the data.)\n",
    "\n",
    "Movie title and year of release are in the same column. Create a new variable that represents year of release, as a four-digit number.\n",
    "\n",
    "#### Exercise 2\n",
    "\n",
    "Create a histogram of year of release. How would you describe the shape of the distribution? When were the most movies released?\n",
    "\n",
    "#### Exercise 3\n",
    "\n",
    "Create a bar chart of the top 10 highest-rated movies.\n",
    "\n",
    "#### Exercise 4\n",
    "\n",
    "Create a variable called `string` that contains the text of each movie's genres, title, and year of release. For example, the value of `string` for `movieID == 3` should be: `\"Adventure Children Fantasy Jumanji (1995)\"`.\n",
    "\n",
    "#### Exercise 5\n",
    "\n",
    "Using the `string` variable, create a tf-idf matrix with `TfidfVectorizer` and `tfv.fit`.\n",
    "\n",
    "#### Exercise 6\n",
    "\n",
    "Use the sigmoid kernel from `scikit-learn` to calculate pairwise similarities between all items in your tf-idf matrix.\n",
    "\n",
    "#### Exercise 7\n",
    "\n",
    "Define a function, `give_recommendation()`, that takes as input the title of a movie and returns the top 10 most similar movies.\n",
    "\n",
    "#### Exercise 8\n",
    "\n",
    "What movies does your recommender system suggest for a user who likes \"Toy Story\" (released in 1995)?\n",
    "\n",
    "#### For 234 Students:\n",
    "\n",
    "#### Exercise 9\n",
    "\n",
    "Now we'll try making content-based recommendations. Turn the data into a CSR matrix using `scipy.sparse`.\n",
    "\n",
    "#### Exercise 10\n",
    "\n",
    "Fit a *k*-nearest neighbors model, using cosine similarity as the distance metric.\n",
    "\n",
    "#### Exercise 11\n",
    "\n",
    "Identify which movies your model deems most similar to \"GoldenEye\" (a James Bond movie, also released in 1995).\n",
    "\n",
    "### Image Classification\n",
    "\n",
    "Now we'll work with the data in `data/Animals`. This dataset, intended for animal image classification, [comes from Kaggle.](https://www.kaggle.com/datasets/borhanitrash/animal-image-classification-dataset) It consists of $3,000$ JPEG RGB images, each of which are 256 x 256 pixels, that have been divided into three classes with $1,000$ images in each class. The classes are `cats`, `dogs`, and `snakes`.\n",
    "\n",
    "#### Exercise 12\n",
    "\n",
    "Randomly select $150$ images of cats, $150$ images of dogs, and $150$ images of snakes. Set these aside in another directory labeled `test_images` to be your testing set. Using the same approach, randomly select another $150$ images from each class, and set these aside in a `validation_images` directory to be your validation set.\n",
    "\n",
    "#### Exercise 13\n",
    "\n",
    "Display a random image from each of the three classes in your training set to verify that the data are set up correctly.\n",
    "\n",
    "#### Exercise 14\n",
    "\n",
    "Using `ImageDataGenerator` and `flow_from_directory`, rescale your training, testing, and validation sets. Load and preprocess your images in batches of size $10$.\n",
    "\n",
    "#### Exercise 15\n",
    "\n",
    "Set up a convolutional neural net (CNN) with 7 layers using `Sequential()`. The layers should be as follows:\n",
    "\n",
    "1. 2D convolutional input layer with a ReLU activation function;\n",
    "2. Max pooling layer for 2D spatial data;\n",
    "3. 2D convolutional layer with ReLU activation;\n",
    "4. Max pooling layer for 2D spatial data;\n",
    "5. Flattening layer;\n",
    "6. Dense layer with $128$ units and ReLU activation;\n",
    "7. Dense output layer with softmax activation.\n",
    "\n",
    "#### Exercise 16\n",
    "\n",
    "Using Adam and categorical cross-entropy, fit the network you've created and let it run for $12$ epochs.\n",
    "\n",
    "#### Exercise 17\n",
    "\n",
    "Create a plot of the accuracy and loss by the number of epochs.\n",
    "\n",
    "#### For 234 Students:\n",
    "\n",
    "#### Exercise 18\n",
    "\n",
    "Look at your model's accuracy on your testing set. How did it do?\n",
    "\n",
    "#### Exercise 19\n",
    "\n",
    "Generate your model's prediction for a random image from the dataset.\n",
    "\n",
    "#### Exercise 20\n",
    "\n",
    "Create a confusion matrix using your testing set. Visualize the matrix as a heat map. Which classes was your model best at predicting? Which was it worst at predicting? How do you know?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
